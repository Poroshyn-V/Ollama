#!/bin/bash

# Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ollama Ğ² Ñ„Ğ¾Ğ½Ğµ
echo "ğŸš€ Starting Ollama server..."
ollama serve &

# Ğ–Ğ´ĞµĞ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° ÑĞµÑ€Ğ²ĞµÑ€Ğ°
echo "â³ Waiting for Ollama to start..."
sleep 15

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ ÑĞµÑ€Ğ²ĞµÑ€ Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ğ»ÑÑ
echo "ğŸ” Checking Ollama server status..."
for i in {1..10}; do
  if curl -f http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âœ… Ollama server is running!"
    break
  else
    echo "â³ Waiting for server... ($i/10)"
    sleep 5
  fi
done

# Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
echo "ğŸ“¦ Installing AI models..."

echo "ğŸ¤ Installing Whisper for transcription..."
ollama pull whisper

echo "ğŸ§  Installing Llama 3 for text analysis..."
ollama pull llama3:8b

echo "ğŸ’¡ Installing Mistral for content generation..."
ollama pull mistral:7b

echo "ğŸ”§ Installing Code Llama for code analysis..."
ollama pull codellama:7b

echo "âœ… All models installed successfully!"
echo "ğŸš€ Ollama service is ready!"

# Ğ”ĞµÑ€Ğ¶Ğ¸Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ğ¼
wait
